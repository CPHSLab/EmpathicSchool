# Facial & Biometric Signal Processing Toolkit

A collection of Python scripts to:

1. **Extract 68 facial landmarks** from videos
2. **Compute Facial Action Units (AUs)** from landmark CSVs
3. **Synchronize â€œemotionâ€ (XCEPTION) bins with HR/EDA/TEMP**, generating labeled time-series
4. **Window & featurize** the combined data for machine learning

---

## ğŸ“‚ Repository Layout

```
.
â”œâ”€â”€ models/
â”‚   â””â”€â”€ shape_predictor_68_face_landmarks.dat
â”œâ”€â”€ dataset/                   # raw videos
â”‚   â”œâ”€â”€ s1/ â€¦ s30/
â”‚   â”‚   â”œâ”€â”€ T1.mp4
â”‚   â””â”€â”€ â€¦
â”œâ”€â”€ 30hz_labeled_scaled/       # landmark CSVs input
â”‚   â”œâ”€â”€ s1/ â€¦ s30/
â”‚   â”‚   â””â”€â”€ T1.csv
â”œâ”€â”€ 30hz_full/                 # AU CSVs output
â”œâ”€â”€ Cropped/                   # emotion data
â”‚   â”œâ”€â”€ bioSignals_sep/
â”‚   â”‚   â”œâ”€â”€ <subject>/T1HR.csv, T1EDA.csv, T1TEMP.csv, â€¦
â”‚   â”œâ”€â”€ <subject1>/subject1V1XCEPTION.xlsx
â”‚   â””â”€â”€ â€¦
â”œâ”€â”€ Labels/                    # Excel stress labels per subject
â”‚   â””â”€â”€ <subject>.xlsx
â”œâ”€â”€ Synch/                     # synchronized emotion+bio outputs
â”œâ”€â”€ Emotions.csv               # merged emotion+bio signals for all users
â”œâ”€â”€ 68landmarksgenerator.py
â”œâ”€â”€ faugenerator.py
â”œâ”€â”€ combine.py
â”œâ”€â”€ featuregenerator.py
â””â”€â”€ README.md


## âš™ï¸ Installation

1. **Clone** and enter repo:

   ```bash
   git clone <your-repo-url>
   cd <your-repo-name>
   ```

2. **Create a virtualenv** (optional but recommended):

   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   ```

3. **Install dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

   > If you donâ€™t have a `requirements.txt`, you can install directly:
   >
   > ```bash
   > pip install numpy pandas scipy scikit-learn opencv-python dlib pandarallel tqdm openpyxl
   > ```

4. **Download the DLIB model**
   Place `shape_predictor_68_face_landmarks.dat` under `models/`.
   You can get it from: [http://dlib.net/files/shape\_predictor\_68\_face\_landmarks.dat.bz2](http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2)

---

## ğŸš€ Usage

### 1. Extract 68-landmarks from videos

```bash
python 68landmarksgenerator.py
```

* **Input**: `dataset/s1â€¦s30/*.mp4|.avi`
* **Output**: `dataset/sX/<video>.csv` (columns: `timestamp, landmark_0_x, landmark_0_y, â€¦, landmark_67_y`)

### 2. Generate Facial Action Units (AUs)

```bash
python faugenerator.py
```

* **Input**: `30hz_labeled_scaled/s1â€¦s30/*.csv` (landmark CSVs)
* **Output**: `30hz_full/sX/*.csv` (original cols + AU features)

### 3. Synchronize Emotion & Biometric Signals

```bash
python combine.py
```

* **Input**:

  * `Cropped/<subject>/<subject>V<task>XCEPTION.xlsx`
  * `Cropped/bioSignals_sep/<subject>/T<task>{HR,EDA,TEMP}.csv`
  * `Labels/<subject>.xlsx`
* **Output**: `Significance/<subject>/<subject>T<task>.csv`
  (columns: time-bins, averaged emotions, hr, eda, temp, `stress` label)

### 4. Window & Featurize for ML

```bash
python featuregenerator.py
```

* **Input**: `Emotions.csv`
* **Output**: `majid.csv`

  * Sliding windows (40 samples, step 20)
  * Stats: emotion means, EDA/HR/TEMP min/max/mean/std/skew/kurtosis/peaks, RMS, durations, binned `stress_label`, `user`

---

## ğŸ“ Requirements

* **Python** â‰¥ 3.7
* **Key packages**:

  * `numpy`, `pandas`, `scipy`, `scikit-learn`
  * `opencv-python`, `dlib`, `pandarallel`, `tqdm`, `openpyxl`

Make sure your directory structure matches the layout above before running.

---

## ğŸ“– Tips

* Scripts are wrapped in `if __name__=="__main__":` so you can also import their functions into other workflows.
* Adjust constants (e.g. window size, folder names) directly at the top of each script.
* Monitor console output for skipped files or errors.
